import keras
from keras.models import Sequential
from keras import layers
from keras.layers import Dense,Embedding, LSTM
from keras import Input
from keras.layers.normalization import BatchNormalization
from keras.models import Sequential,Model
from keras import backend as K
from keras import regularizers
import numpy as np
from keras.optimizers import adam
import pandas as pd
import csv
from keras import callbacks
import getdata
import getdatabiaozhunhuaA
def mean_squared_logarithmic_error(y_true, y_pred):
    return K.mean(K.square(K.log(K.abs(y_true-y_pred))))
def norm(data):
    data_train = data[:, 1:]
    data_train = (data_train - data[:, 1:].mean()) / data[:, 1:].std()
    data[:, 1:] = data_train
    return data

input1,input2,input4,input6,label1,label2,label4,label6=getdatabiaozhunhuaA.getdata()
#输入
infection_input=Input(shape=(None,1))
new_input=Input(shape=(None,1))
#density_input=Input(shape=(None,1))
m_i_input=Input(shape=(None,8))

#m=LSTM(128,input_shape=(None,8),return_sequences=True,activation="relu")(m_i_input)
m=LSTM(128,return_sequences=True,activation="relu")(m_i_input)
m=Dense(256,activation='relu')(m)
m=Dense(128,activation='relu')(m)
migration_output=Dense(1)(m)
infection_output=Dense(1)(m)

concatenated=layers.concatenate([migration_output,infection_output,infection_input,new_input],axis=-1)
print(concatenated.shape)
x = LSTM(128,input_shape=(None,5),return_sequences=True,activation="relu")(concatenated)
x = LSTM(128,activation="relu")(x)
x=Dense(128, activation='relu')(x)
x=Dense(128, activation='relu')(x)
x=Dense(64, activation='relu')(x)
x=Dense(64, activation='relu')(x)
x=Dense(64, activation='relu')(x)
x=Dense(64, activation='relu')(x)

#输出
infection_prediction = Dense(1, name='infection')(x)
new_prediction = Dense(1, name='new')(x)
m_i_prediction=Dense(8, name='m_i')(x)
callback_list=[
    callbacks.EarlyStopping(monitor="val_new_loss",patience=500),
    callbacks.ModelCheckpoint(filepath="zhibing9_k8_morelstm2A21.h5",monitor="val_new_loss",save_best_only=True),#zhibing9_k8_morelstm2
    callbacks.ReduceLROnPlateau(monitor="loss_new_loss",factor=0.9,verbose=1,patience=10)
]
model = Model(inputs=[infection_input, new_input,m_i_input], outputs=[infection_prediction, new_prediction,m_i_prediction],name='m')
model.summary()
model.compile(optimizer=adam(), loss='mae')
model.fit([input1[:],input2[:],input4[:]], [label1[:], label2[:],label4[:]],epochs=1000000, batch_size=128,callbacks=callback_list,validation_split=0.3)
#model.fit([input1[:100*40],input2[:100*40],input4[:100*40]], [label1[:100*40], label2[:100*40],label3[:100*40]],epochs=1000000, batch_size=128,callbacks=callback_list,validation_split=0.3)
#print(model.evaluate([input1[100*(45-n):],input2[100*(45-n):],input4[100*(45-n):]], [label1[100*(45-n):], label2[100*(45-n):],label3[100*(45-n):]]))
